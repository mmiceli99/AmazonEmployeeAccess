vData <- vroom("C:/School/Stat348/KaggleBikeShare/test.csv")
View(vData)
vData <- vData %>%
mutate(as.factor(season))
View(vData)
vData <- vroom("C:/School/Stat348/KaggleBikeShare/test.csv")
View(vData)
vData <- vroom("C:/School/Stat348/KaggleBikeShare/test.csv")
vData$season <- as.factor(vData$season)
vData$holiday <- as.factor(vData$holiday)
vData$workingday <- as.factor(vData$workingday)
vData$weather <- as.factor(vData$weather)
vData <- vroom("C:/School/Stat348/KaggleBikeShare/train.csv")
vData$season <- as.factor(vData$season)
vData$holiday <- as.factor(vData$holiday)
vData$workingday <- as.factor(vData$workingday)
vData$weather <- as.factor(vData$weather)
DataExplorer::plot_intro(vData)
install.packages("DataExplorer")
DataExplorer::plot_intro(vData)
plot_bar <- DataExplorer::plot_bar(vData)
plot_hist <- DataExplorer::plot_histogram(vData)
plot_missing <- DataExplorer::plot_missing(vData)
ggplot(vData) %>%
aes(x=vData$temp, y=vData$windspeed)
ggplot(vData) %>%
aes(x=temp, y=windspeed)
ggplot(vData) %>%
aes(x=temp, y=windspeed) + geom_point()
ggplot(vData, aes(x=temp, y=windspeed)) %>%
geom_point()
ggplot(vData, aes(x=temp, y=windspeed)) +
geom_point()
ggplot(vData, aes(x=temp, y=windspeed)) +
geom_point()
corr(vData)
cor(vData)
ggplot(vData, aes(x=humidity, y=windspeed)) +
geom_point()
ggplot(vData, aes(x=temp, y=atemp)) +
geom_point()
temp_atemp <- ggplot(vData, aes(x=temp, y=atemp)) +
geom_point()
GGally::ggpairs(vData)
install.packages("GGally")
GGally::ggpairs(vData)
plot_intro <- DataExplorer::plot_intro(vData)
plot_bar <- DataExplorer::plot_bar(vData)
plot_hist <- DataExplorer::plot_histogram(vData)
plot_missing <- DataExplorer::plot_missing(vData)
View(vData)
d
date_temp <- ggplot(vData, aes(x=vData$datetime, y=temp)) +
geom_point()
date_temp
date_temp <- ggplot(vData, aes(x=vData$datetime, y=temp)) +
geom_point() +
geom_smooth()
date_temp
date_temp <- ggplot(vData, aes(x=vData$datetime, y=temp)) +
geom_point() +
geom_smooth(se=false)
plot_hist
plot_bar
box_humid <- ggplot(vData, aes(x=humidity))+
geom_boxplot()
box_humid
box_humid <- ggplot(vData, aes(x=humidity, y=season))+
geom_boxplot()
box_humid
weather_bar <- ggplot(vData, aes(x=weather)) +
geom_bar()
weather_bar
library(patchwork)
temp_atemp + date_temp
(temp_atemp + date_temp) / (box_humid + weather_bar)
plot_intro + plot_bar
plot_intro + plot_bar
install.packages('ggchernoff')
install.packages('ggChernoff')
?ggChernoff
flights
read.csv("C:/School/Stat386/lab-4-pandas-flights-mmiceli99/planes.csv")
flights <- read.csv("C:/School/Stat386/lab-4-pandas-flights-mmiceli99/planes.csv")
library(tidyverse)
library(ggChernoff)
ggplot(flights) +
ggChernoff()
ggplot(flights) +
geom_chernoff()
view(flights)
?geom_chernoff
ggplot(flights) +
geom_chernoff(aes(x=tailnum, y =c(year, seats, speed, engines)))
ggplot(flights) +
geom_chernoff(aes(x=tailnum, y =c(year)))
read.csv("C:/School/Stat348/Amazon/train.csv")
ama_train <- vroom("C:/School/Stat348/Amazon/train.csv")
library(vroom)
library(tidyverse)
library(tidymodels)
ama_train <- vroom("C:/School/Stat348/Amazon/train.csv")
View(ama_train)
library(randomForest)
install.packages('randomForest')
library(randomForest)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
library(randomForest)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
ggplot(ama_train) +
geom_bar(aes(x=ama_train$ACTION))
ggplot(ama_train) +
geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .05) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
model <- randomForest(ACTION ~ ., data = ama_train)
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(model) %>%
fit(data=ama_train)
View(baked)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .05) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
View(baked)
source("C:/School/Stat348/AmazonEmployeeAccess/Amazon_eda.R")
ggplot(data = ama_train) +
geom_count(mapping = aes(x = ama_train$ROLE_ROLLUP_1, y = ama_train$ROLE_ROLLUP_1))
ggplot(data = ama_train) +
geom_count(mapping = aes(x = ama_train$ROLE_ROLLUP_1, y = ama_train$ROLE_TITLE))
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
ggplot(ama_train) +
geom_bar(aes(x=ama_train$ACTION))
ggplot(ama_train) +
geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
# ggplot(ama_train) +
#   geom_bar(aes(x=ama_train$ACTION))
#
# ggplot(ama_train) +
#   geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
#
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
model <- glm(ACTION ~ ., data = ama_train, family = "binomial")
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
# Fit logistic regression model
my_mod <- glm(ACTION ~ ., data = ama_train, family = "binomial")
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
# Fit logistic regression model
my_mod <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate( Id = row_number()) %>%
rename(Action=.pred) %>%
select(Id, Action)
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) #%>%
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ama_train$ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) #%>%
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=2) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c(2)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c(1,2)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c(1:2)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c('1', '2')) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c('1', '0')) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c('0', '1')) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(Action = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
# Fit logistic regression model
my_model <- logistic_reg(Action ~ .) %>%
set_engine('glm')
# Fit logistic regression model
my_model <- logistic_reg(Action ~ .) %>%
set_engine('glm')
?logicstic_reg
?logicstic_reg()
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) #%>%
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate(Id = row_number()) %>%
rename(ACTION =.pred) %>%
select(Id, Action)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
# ggplot(ama_train) +
#   geom_bar(aes(x=ama_train$ACTION))
#
# ggplot(ama_train) +
#   geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate(Id = row_number()) %>%
rename(ACTION =.pred) %>%
select(Id, Action)
my_recipe <- recipe(ACTION ~ ., data = ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
# Apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = ama_train)
my_recipe <- recipe(ACTION ~ ., data = ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
# Apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate(Id = row_number()) %>%
rename(ACTION =.pred) %>%
select(Id, Action)
my_recipe <- recipe(ACTION ~ ., data = ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
# Apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = ama_train)
parallel::numcores
parallel::detectCores()
library(vroom)
ama_train <- vroom("./train.csv")
setwd("C:/School/Stat348/AmazonEmployeeAccess")
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
1-.87434
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
library(discrim)
library(naivebayes)
library(doParallel)
#parallel::detectCores() #How many cores do I have?
#cl <- makePSOCKcluster(4) # num_cores to use
#registerDoParallel(cl)
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
ama_train <- ama_train %>%
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
#step_mutate_at(ACTION, fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
#step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
nb_model <- naive_Bayes(Laplace=tune(), smoothness=tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes") # install discrim library for the naivebayes eng
nb_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(nb_model)
## Grid of values to tune over
tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
folds <- vfold_cv(ama_train, v = 5, repeats=1)
## Run the CV
CV_results <- nb_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
## Find Best Tuning Parameters
bestTune <- CV_results %>%
select_best("roc_auc")
## Finalize the Workflow & fit it
final_wf <-
nb_wf %>%
finalize_workflow(bestTune) %>%
fit(data=ama_train)
## Predict
ama_predictions <- predict(final_wf, new_data=ama_test, type='prob') %>%
mutate( Id = row_number()) %>%
rename(Action=.pred_1) %>%
select(Id, Action)
vroom_write(x=ama_predictions, file="./naiveBayes.csv", delim=",")
#stopCluster(cl)
ama_predictions
View(ama_predictions)
