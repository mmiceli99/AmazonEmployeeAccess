step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
model <- randomForest(ACTION ~ ., data = ama_train)
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(model) %>%
fit(data=ama_train)
View(baked)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .05) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
View(baked)
source("C:/School/Stat348/AmazonEmployeeAccess/Amazon_eda.R")
ggplot(data = ama_train) +
geom_count(mapping = aes(x = ama_train$ROLE_ROLLUP_1, y = ama_train$ROLE_ROLLUP_1))
ggplot(data = ama_train) +
geom_count(mapping = aes(x = ama_train$ROLE_ROLLUP_1, y = ama_train$ROLE_TITLE))
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
ggplot(ama_train) +
geom_bar(aes(x=ama_train$ACTION))
ggplot(ama_train) +
geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
# ggplot(ama_train) +
#   geom_bar(aes(x=ama_train$ACTION))
#
# ggplot(ama_train) +
#   geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
#
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
model <- glm(ACTION ~ ., data = ama_train, family = "binomial")
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
# Fit logistic regression model
my_mod <- glm(ACTION ~ ., data = ama_train, family = "binomial")
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
# Fit logistic regression model
my_mod <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate( Id = row_number()) %>%
rename(Action=.pred) %>%
select(Id, Action)
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data=ama_train)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) #%>%
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ama_train$ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) #%>%
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=2) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c(2)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c(1,2)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c(1:2)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c('1', '2')) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c('1', '0')) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_num2factor(ACTION, levels=c('0', '1')) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(Action = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
# Fit logistic regression model
my_model <- logistic_reg(Action ~ .) %>%
set_engine('glm')
# Fit logistic regression model
my_model <- logistic_reg(Action ~ .) %>%
set_engine('glm')
?logicstic_reg
?logicstic_reg()
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) #%>%
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate(Id = row_number()) %>%
rename(ACTION =.pred) %>%
select(Id, Action)
ama_train <- vroom("C:/School/Stat348/AmazonEmployeeAccess/train.csv")
ama_test <- vroom("C:/School/Stat348/AmazonEmployeeAccess/test.csv")
# ggplot(ama_train) +
#   geom_bar(aes(x=ama_train$ACTION))
#
# ggplot(ama_train) +
#   geom_box(aes(x=ama_train$RESOURCE, y = ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
step_other(all_nominal_predictors(), threshold = .01) %>% # combines categorical values that occur <5% into an "other" value
step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data=ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate(Id = row_number()) %>%
rename(ACTION =.pred) %>%
select(Id, Action)
my_recipe <- recipe(ACTION ~ ., data = ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
# Apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = ama_train)
my_recipe <- recipe(ACTION ~ ., data = ama_train) %>%
step_mutate(ACTION = as.factor(ACTION)) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
# Apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = ama_train)
ama_predictions <- predict(ama_workflow, new_data=ama_test) %>%
mutate(Id = row_number()) %>%
rename(ACTION =.pred) %>%
select(Id, Action)
my_recipe <- recipe(ACTION ~ ., data = ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = 0.01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
# Apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
# Fit logistic regression model
my_model <- logistic_reg() %>%
set_engine('glm')
ama_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_model) %>%
fit(data = ama_train)
parallel::numcores
parallel::detectCores()
library(vroom)
ama_train <- vroom("./train.csv")
setwd("C:/School/Stat348/AmazonEmployeeAccess")
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
1-.87434
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
library(discrim)
library(naivebayes)
library(doParallel)
#parallel::detectCores() #How many cores do I have?
#cl <- makePSOCKcluster(4) # num_cores to use
#registerDoParallel(cl)
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
ama_train <- ama_train %>%
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
#step_mutate_at(ACTION, fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
#step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
nb_model <- naive_Bayes(Laplace=tune(), smoothness=tune()) %>%
set_mode("classification") %>%
set_engine("naivebayes") # install discrim library for the naivebayes eng
nb_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(nb_model)
## Grid of values to tune over
tuning_grid <- grid_regular(Laplace(),
smoothness(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
folds <- vfold_cv(ama_train, v = 5, repeats=1)
## Run the CV
CV_results <- nb_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
## Find Best Tuning Parameters
bestTune <- CV_results %>%
select_best("roc_auc")
## Finalize the Workflow & fit it
final_wf <-
nb_wf %>%
finalize_workflow(bestTune) %>%
fit(data=ama_train)
## Predict
ama_predictions <- predict(final_wf, new_data=ama_test, type='prob') %>%
mutate( Id = row_number()) %>%
rename(Action=.pred_1) %>%
select(Id, Action)
vroom_write(x=ama_predictions, file="./naiveBayes.csv", delim=",")
#stopCluster(cl)
ama_predictions
View(ama_predictions)
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
library(discrim)
library(naivebayes)
#(doParallel)
#parallel::detectCores() #How many cores do I have?
#cl <- makePSOCKcluster(4) # num_cores to use
#registerDoParallel(cl)
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
ama_train <- ama_train %>%
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
#step_mutate_at(ACTION, fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
#step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
## knn model
knn_model <- nearest_neighbor(neighbors=tune()) %>% # set or tune
set_mode("classification") %>%
set_engine("kknn")
knn_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(knn_model)
## Grid of values to tune over
tuning_grid <- grid_regular(neighbors(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
folds <- vfold_cv(ama_train, v = 5, repeats=1)
## Run the CV
CV_results <- knn_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
install.packages('kknn')
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
library(discrim)
library(naivebayes)
library(kknn)
#(doParallel)
#parallel::detectCores() #How many cores do I have?
#cl <- makePSOCKcluster(4) # num_cores to use
#registerDoParallel(cl)
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
ama_train <- ama_train %>%
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
#step_mutate_at(ACTION, fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
#step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# also step_lencode_glm() and step_lencode_bayes()
# NOTE: some of these step functions are not appropriate to use together
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
## knn model
knn_model <- nearest_neighbor(neighbors=tune()) %>% # set or tune
set_mode("classification") %>%
set_engine("kknn")
knn_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(knn_model)
## Grid of values to tune over
tuning_grid <- grid_regular(neighbors(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
folds <- vfold_cv(ama_train, v = 5, repeats=1)
## Run the CV
CV_results <- knn_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
## Find Best Tuning Parameters
bestTune <- CV_results %>%
select_best("roc_auc")
## Finalize the Workflow & fit it
final_wf <-
knn_wf %>%
finalize_workflow(bestTune) %>%
fit(data=ama_train)
## Predict
ama_predictions <- predict(final_wf, new_data=ama_test, type='prob') %>%
mutate( Id = row_number()) %>%
rename(Action=.pred_1) %>%
select(Id, Action)
vroom_write(x=ama_predictions, file="./knn.csv", delim=",")
#stopCluster(cl)
library(vroom)
library(tidyverse)
library(tidymodels)
library(embed)
library(discrim)
library(naivebayes)
library(kknn)
ama_train <- vroom("./train.csv")
ama_test <- vroom("./test.csv")
ama_train <- ama_train %>%
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data=ama_train) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
#step_mutate_at(ACTION, fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .001) %>%
step_normalize() %>%# combines categorical values that occur <5% into an "other" value
#step_dummy(all_nominal_predictors()) %>% # dummy variable encoding
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #target encoding
# apply the recipe to your data
prep <- prep(my_recipe)
baked <- bake(prep, new_data = ama_train)
